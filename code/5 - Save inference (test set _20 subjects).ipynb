{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "You DON'T need a GPU to run inference. It is fast even in a CPU.\n",
    "\n",
    "This notebook segments data indicating by the subject numbers in testing_subjects.txt containing 20 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as ni\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import argparse\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from CNNs.unet import UNet\n",
    "from Utils.transforms import My_transforms\n",
    "\n",
    "import Utils.view as vi\n",
    "import Utils.Metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nii_file(file_path):\n",
    "    data = ni.load(file_path)\n",
    "    volume = np.nan_to_num(data.get_data().squeeze())\n",
    "    return volume\n",
    "\n",
    "def load_files(file_paths, d_type=None):\n",
    "    images = []\n",
    "    for path in file_paths:\n",
    "        if d_type == None:\n",
    "            images.append(load_nii_file(path))\n",
    "        else: \n",
    "            images.append(load_nii_file(path).astype(d_type))\n",
    "    return images\n",
    "\n",
    "\n",
    "def to_onehot(matrix, labels=[], single_foregound_lable=True, background_channel=True, onehot_type=np.dtype(np.float32)):\n",
    "    matrix = np.around(matrix)\n",
    "    if len(labels) == 0:\n",
    "        labels = np.unique(matrix) \n",
    "        labels = labels[1::]\n",
    "    \n",
    "    mask = np.zeros(matrix.shape, dtype=onehot_type)\n",
    "    for i, label in enumerate(labels):\n",
    "        mask += ((matrix == label) * (i+1))\n",
    "   \n",
    "    if single_foregound_lable:\n",
    "        mask = (mask > 0)\n",
    "        labels = [1]\n",
    "        \n",
    "    labels_len = len(labels)        \n",
    "        \n",
    "    onehot = np.zeros((labels_len+1,) + matrix.shape, dtype=onehot_type) \n",
    "    for i in range(mask.max()+1):\n",
    "        onehot[i] = (mask == i)  \n",
    "        \n",
    "    if background_channel == False:\n",
    "        onehot = onehot[1::] \n",
    "        \n",
    "       \n",
    "    return mask, onehot, labels\n",
    "\n",
    "class Segmentor(pl.LightningModule):\n",
    "    def __init__(self, hparams: argparse.Namespace):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters(hparams)        \n",
    "\n",
    "        if \"unet\" in self.hparams.cnn_architecture:\n",
    "            architecture = UNet(nin_channels=self.hparams.n_inchannels, \n",
    "                                nout_channels=self.hparams.n_outchannels, \n",
    "                                init_features=self.hparams.init_features)\n",
    "        elif self.hparams.cnn_architecture == \"coedet\":\n",
    "            architecture = CoEDET(nin=self.hparams.n_inchannels, nout=self.hparams.n_outchannels, \n",
    "                                  apply_sigmoid=self.hparams.apply_sigmoid)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported cnn_architecture {self.hparams.cnn_architecture}\")\n",
    "\n",
    "#         self.model = architecture(self.hparams)\n",
    "        self.model = architecture\n",
    "    \n",
    "        \n",
    "        ttransform_scale=None\n",
    "        ttransform_angle=None\n",
    "        ttransform_flip_prob=None\n",
    "        ttransform_sigma=None\n",
    "        ttransform_ens_treshold=None\n",
    "        if \"taug_scale\" in self.hparams:\n",
    "            ttransform_scale = self.hparams.taug_scale\n",
    "        if \"taug_angle\" in self.hparams:\n",
    "            ttransform_angle = self.hparams.taug_angle\n",
    "        if \"taug_flip_prob\" in self.hparams:\n",
    "            ttransform_flip_prob = self.hparams.taug_flip_prob\n",
    "        if \"taug_sigma\" in self.hparams:\n",
    "            ttransform_sigma = self.hparams.taug_sigma\n",
    "        if \"taug_ens_treshold\" in self.hparams:\n",
    "            ttransform_ens_treshold = self.hparams.aug_ens_treshold\n",
    "        self.train_transforms = My_transforms(scale=ttransform_scale,\n",
    "                                         angle=ttransform_angle,\n",
    "                                         flip_prob=ttransform_flip_prob,\n",
    "                                         sigma=ttransform_sigma,\n",
    "                                         ens_treshold=ttransform_ens_treshold\n",
    "                                        )\n",
    "        vtransform_scale=None\n",
    "        vtransform_angle=None\n",
    "        vtransform_flip_prob=None\n",
    "        vtransform_sigma=None\n",
    "        vtransform_ens_treshold=None\n",
    "        if \"vaug_scale\" in self.hparams:\n",
    "            ttransform_scale = self.hparams.vaug_scale\n",
    "        if \"vaug_angle\" in self.hparams:\n",
    "            ttransform_angle = self.hparams.vaug_angle\n",
    "        if \"vaug_flip_prob\" in self.hparams:\n",
    "            ttransform_flip_prob = self.hparams.vaug_flip_prob\n",
    "        if \"vaug_sigma\" in self.hparams:\n",
    "            ttransform_sigma = self.hparams.vaug_sigma\n",
    "        if \"vaug_ens_treshold\" in self.hparams:\n",
    "            ttransform_ens_treshold = self.hparams.vaug_ens_treshold\n",
    "        self.val_transforms = My_transforms(scale=vtransform_scale,\n",
    "                                         angle=vtransform_angle,\n",
    "                                         flip_prob=vtransform_flip_prob,\n",
    "                                         sigma=vtransform_sigma,\n",
    "                                         ens_treshold=vtransform_ens_treshold\n",
    "                                        )\n",
    "        \n",
    "  \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        loss = None\n",
    "\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)\n",
    "#         print('x.shape = ', x.shape)\n",
    "#         print('y.shape = ', y.shape)\n",
    "#         print('logits.shape = ', logits.shape)\n",
    "\n",
    "        loss = CombinedLoss(logits, y, \n",
    "                            self.hparams.train_loss_funcs, \n",
    "                            self.hparams.lossweighs,\n",
    "                            func_weights=self.hparams.func_weights)\n",
    "\n",
    "        if self.hparams.train_metric == 'DiceMetric_weighs':\n",
    "            train_metric = DiceMetric_weighs(y_pred=logits, y_true=y,\n",
    "                                             weights=self.hparams.train_metricweighs, treshold=0.5)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric {self.hparams.train_metric}\")\n",
    "\n",
    "        self.log(\"loss\", loss, on_epoch=True, on_step=True)\n",
    "        self.log(\"train_metric\", train_metric, on_epoch=True, on_step=False)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        logits = None\n",
    "\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "#         loss = self.lossfunc(logits, y)\n",
    "\n",
    "        loss = CombinedLoss(logits, y, \n",
    "                            self.hparams.val_loss_funcs, \n",
    "                            self.hparams.lossweighs,\n",
    "                            func_weights=self.hparams.func_weights)\n",
    "    \n",
    "        if self.hparams.val_metric == 'DiceMetric_weighs':\n",
    "            val_metric = DiceMetric_weighs(y_pred=logits, y_true=y,\n",
    "                                             weights=self.hparams.val_metricweighs, treshold=0.5)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric {self.hparams.val_metric}\")\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_metric\", val_metric, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"learning_rate_test\", self.optimizer.param_groups[0]['lr'], on_epoch=True, on_step=False, prog_bar=False)\n",
    "\n",
    "    \n",
    "    def get_optimizer_by_name(self, name, lr):\n",
    "        '''\n",
    "        Select optimizer and scheduling strategy according to hparams.\n",
    "        '''\n",
    "        if name == \"Adam\":\n",
    "            return Adam(self.model.parameters(), lr=lr)\n",
    "        elif name == \"SGD\":\n",
    "            return SGD(self.model.parameters(), lr=lr)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported optimizer: {name}\")\n",
    "            \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        '''\n",
    "        Select optimizer and scheduling strategy according to hparams.\n",
    "        '''\n",
    "        optimizer = self.get_optimizer_by_name(self.hparams.opt_name, \n",
    "                                               self.hparams.lr)\n",
    "\n",
    "        if self.hparams.lr_decay_policy == 'step':\n",
    "            scheduler = StepLR(optimizer, self.hparams.scheduling_patience_lrepochs, self.hparams.lr_decay_factor, verbose=True)\n",
    "            print('STEP - scheduling_patience_lrepochs = ', self.hparams.scheduling_patience_lrepochs, ' lr_decay_factor = ', self.hparams.lr_decay_factor)\n",
    "        elif self.hparams.lr_decay_policy == 'plateau':\n",
    "            print('PLATEAU - scheduling_patience_lrepochs = ', self.hparams.scheduling_patience_lrepochs, ' lr_decay_factor = ', self.hparams.lr_decay_factor)\n",
    "\n",
    "            self.optimizer = optimizer\n",
    "            lr_scheduler =  {\n",
    "                           'scheduler': ReduceLROnPlateau(optimizer),\n",
    "                           'mode': self.hparams.lr_decay_mode,\n",
    "                           'factor': self.hparams.lr_decay_factor,\n",
    "                           'patience': self.hparams.scheduling_patience_lrepochs,\n",
    "                           'threshold': self.hparams.learning_threshold,\n",
    "                           'threshold_mode': self.hparams.lr_decay_threshold_mode,\n",
    "                           'cooldown': 0,\n",
    "#                            'min_lr': self.hparams.lr,\n",
    "                           'min_lr': self.hparams.min_lr,\n",
    "                           'eps': self.hparams.eps,\n",
    "                           'monitor': self.hparams.monitor,\n",
    "                           'verbose': True\n",
    "                           }\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported lr_decay_policy {self.hparams.lr_decay_policy}\")\n",
    "            \n",
    "\n",
    "        return [optimizer], [scheduler] \n",
    "    \n",
    "\n",
    "def find_checkpoint(pre_trained_ckpt_folder,view,input_channels):\n",
    "    '''\n",
    "    Finds correct checkpoint from given view\n",
    "    '''\n",
    "    ckpt_candidates = glob(f\"checkpoints/{pre_trained_ckpt_folder}/*{view}_{''.join(input_channels)}*.ckpt\")\n",
    "    assert len(ckpt_candidates) == 1, \"More than one checkpoint elegible, leave only one checkpoint for each view and data combination.\"\n",
    "#     print(f\"Found following {view} checkpoint: {ckpt_candidates}.\")\n",
    "    print(view)\n",
    "    return ckpt_candidates[0]\n",
    "\n",
    "def ch2sufix(input_channels):\n",
    "    img_paths = []\n",
    "    for in_ch in input_channels:\n",
    "        if in_ch == 'evalue1':\n",
    "            img_paths.append('diffusion/evalue1.nii.gz')\n",
    "        if in_ch == 'FA':\n",
    "            img_paths.append('diffusion/FA.nii.gz')\n",
    "        if in_ch == 'RD':\n",
    "            img_paths.append('diffusion/RD.nii.gz')\n",
    "        if in_ch == 'MD':\n",
    "            img_paths.append('diffusion/MD.nii.gz')\n",
    "        if in_ch == 'T1':\n",
    "            img_paths.append('T1w_acpc_dc_restore_1.25.nii.gz')\n",
    "    return img_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Definition of model parameters and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "pre_trained_ckpt_folder = \"fine_tuning_unet_single_label_freeze/\"\n",
    "dataset_folder = './Data/HCP_processed_data/'\n",
    "subject_list = 'testing_subjects.txt'\n",
    "prediction_folder = f\"./Predictions/{pre_trained_ckpt_folder}\"\n",
    "\n",
    "# Experiment definition\n",
    "Slice_views = ['axial', 'coronal', 'sagittal']\n",
    "# Slice_views = ['axial']\n",
    "# Slice_views = ['coronal']\n",
    "# Slice_views = ['sagittal']\n",
    "\n",
    "\n",
    "# input_channels=['evalue1', 'FA', 'RD', 'MD', 'T1']\n",
    "# input_channels=['evalue1', 'FA', 'RD', 'MD']\n",
    "# input_channels=['T1']\n",
    "# input_channels=['FA', 'RD']\n",
    "# input_channels=['FA', 'T1']\n",
    "# input_channels=['FA', 'MD']\n",
    "# input_channels=['FA', 'evalue1']\n",
    "# input_channels=['RD', 'MD']\n",
    "# input_channels=['FA']\n",
    "# input_channels=['MD']\n",
    "# input_channels=['RD']\n",
    "# input_channels=['evalue1']\n",
    "# input_channels=['MD', 'T1']\n",
    "input_channels=['evalue1', 'T1']\n",
    "\n",
    "\n",
    "\n",
    "percentil_filt = 99.98\n",
    "normalize_volumes = [0,1]\n",
    "prediction_threshold = 0.5\n",
    "input_d_type='float32'\n",
    "save_prediction = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Inference and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject =  103010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-21d454a3c31c>:3: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  volume = np.nan_to_num(data.get_data().squeeze())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axial\n",
      "coronal\n",
      "sagittal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:66: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject =  112314\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  129634\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  153025\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  154229\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  160123\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  161630\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  187850\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  191841\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  199251\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  200311\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  268850\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  287248\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  300618\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  352132\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  561444\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  580347\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  604537\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  792564\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "subject =  814649\n",
      "axial\n",
      "coronal\n",
      "sagittal\n",
      "CPU times: user 30min 37s, sys: 4min 36s, total: 35min 13s\n",
      "Wall time: 4min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "dest_folder = f\"{prediction_folder}{'-'.join(Slice_views)}_{''.join(input_channels)}/\"\n",
    "os.makedirs(dest_folder, exist_ok=True)\n",
    "mask_free_sufix = 'FreeSurfer/aparc+aseg_1.25_nearest.nii.gz'\n",
    "subjects = [line.strip() for line in open(subject_list)]\n",
    "\n",
    "MASKS = []\n",
    "STAPLE = []\n",
    "FREE = []\n",
    "FSL = []\n",
    "QUI = []\n",
    "MAN = []\n",
    "PREDICTIONS = []\n",
    "PREDICTIONS_fullsize = []\n",
    "\n",
    "for subject in subjects:\n",
    "    print('subject = ', subject)\n",
    "        \n",
    "    img_paths = ch2sufix(input_channels)\n",
    "    images = load_files([dataset_folder + subject + '/' +  s for s in img_paths])\n",
    "\n",
    "    if percentil_filt > 0:\n",
    "        for i in range(len(images)):\n",
    "            images[i][images[i] > np.percentile(images[i], percentil_filt)] = np.percentile(images[i], percentil_filt)\n",
    "    \n",
    "    if len(normalize_volumes) == 2:\n",
    "        for i in range(len(images)):\n",
    "            images[i] = images[i] * ((normalize_volumes[1]-normalize_volumes[0])/(images[i].max()-images[i].min()))\n",
    "            images[i] = images[i] - images[i].min() + normalize_volumes[0]          \n",
    "   \n",
    "    img_crop = np.array(images)[:, :144, 15:159, :144]\n",
    "    \n",
    "    PREDS = []\n",
    "    for Slice_view in Slice_views:\n",
    "        \n",
    "        # reorient images\n",
    "        if Slice_view == 'axial':\n",
    "            img_crop_reoriented = np.transpose(img_crop, (3, 0, 1, 2))\n",
    "        elif Slice_view == 'coronal':\n",
    "            img_crop_reoriented = np.transpose(img_crop, (2, 0, 1, 3))\n",
    "        elif Slice_view == 'sagittal':\n",
    "            img_crop_reoriented = np.transpose(img_crop, (1, 0, 2, 3))\n",
    "            \n",
    "        model_path = find_checkpoint(pre_trained_ckpt_folder,Slice_view,input_channels)\n",
    "\n",
    "        trained_model = Segmentor.load_from_checkpoint(model_path).eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = trained_model(torch.tensor(img_crop_reoriented)).cpu().numpy()\n",
    "\n",
    "        # reorient images\n",
    "        if Slice_view == 'axial':\n",
    "            preds = np.transpose(preds, (1, 2, 3, 0))\n",
    "        elif Slice_view == 'coronal':\n",
    "            preds = np.transpose(preds, (1, 2, 0, 3))\n",
    "        elif Slice_view == 'sagittal':\n",
    "            preds = np.transpose(preds, (1, 0, 2, 3))\n",
    "\n",
    "        PREDS.append(preds) #prediction for each slice\n",
    "    \n",
    "    prediction = np.zeros(preds.shape)\n",
    "    for pred in PREDS:\n",
    "        prediction = prediction + pred/len(PREDS)\n",
    "    \n",
    "    if save_prediction:\n",
    "        FREE_file = ni.load(dataset_folder + subject + '/' + mask_free_sufix)\n",
    "        FREE_data = FREE_file.get_data()  \n",
    "                            \n",
    "        PREDICTION_fullsize = np.zeros(images[0].shape)\n",
    "        PREDICTION_fullsize[:144, 15:159, :144] = (prediction[1] >= prediction_threshold)  #save only the thalamus channel\n",
    "        PREDICTIONS_fullsize.append(PREDICTION_fullsize)\n",
    "        prediction_file = ni.Nifti1Image(PREDICTION_fullsize.astype(FREE_data.dtype), affine=FREE_file.affine, header=FREE_file.header)\n",
    "        ni.save(prediction_file, dest_folder + subject + '.nii.gz')\n",
    "        \n",
    "    PREDICTIONS.append(np.asarray(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs are saved on the Predictions folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "vi.volume_show(PREDICTIONS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
