{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "You DON'T need a GPU to run inference. It is fast even in a CPU.\n",
    "\n",
    "This notebook segments data indicating by the subject numbers in inference_input.txt. Its pre-loaded with one subjects as an example, however you need to follow the download instructions to get more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100206\r\n"
     ]
    }
   ],
   "source": [
    "!cat inference_input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these subjects should be in the HCP_processed_data, following the organization that results from our pre-processing pipeline (for the T1 and difussion files), as in the example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m./Data/HCP_processed_data/100206\u001b[00m\r\n",
      "├── \u001b[01;34mFSL\u001b[00m\r\n",
      "│   └── \u001b[01;31mT1_first_all_fast_firstseg_1.25_nearest.nii.gz\u001b[00m\r\n",
      "├── \u001b[01;34mFreeSurfer\u001b[00m\r\n",
      "│   └── \u001b[01;31maparc+aseg_1.25_nearest.nii.gz\u001b[00m\r\n",
      "├── \u001b[01;34mQuickNAT\u001b[00m\r\n",
      "│   └── \u001b[01;31msegmentation_acpc_dc_restore_1.25_nearest.nii.gz\u001b[00m\r\n",
      "├── \u001b[01;34mSTAPLE\u001b[00m\r\n",
      "│   └── \u001b[01;31mSTAPLE_th0.5_thalamus_1.25.nii.gz\u001b[00m\r\n",
      "├── \u001b[01;32mT1w_acpc_dc_restore_1.25.nii.gz\u001b[00m\r\n",
      "└── \u001b[01;34mdiffusion\u001b[00m\r\n",
      "    ├── \u001b[01;31mFA.nii.gz\u001b[00m\r\n",
      "    ├── \u001b[01;31mMD.nii.gz\u001b[00m\r\n",
      "    ├── \u001b[01;31mRD.nii.gz\u001b[00m\r\n",
      "    ├── \u001b[01;31mevals.nii.gz\u001b[00m\r\n",
      "    ├── \u001b[01;31mevalue1.nii.gz\u001b[00m\r\n",
      "    └── \u001b[01;31mevecs.nii.gz\u001b[00m\r\n",
      "\r\n",
      "5 directories, 11 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree ./Data/HCP_processed_data/100206"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you download the rest of the data from the benchmark, it should be already in that format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as ni\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from CNNs.unet import UNet\n",
    "from Utils.transforms import My_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nii_file(file_path):\n",
    "    data = ni.load(file_path)\n",
    "    volume = np.nan_to_num(data.get_data().squeeze())\n",
    "    return volume\n",
    "\n",
    "def load_files(file_paths, d_type=None):\n",
    "    images = []\n",
    "    for path in file_paths:\n",
    "        if d_type == None:\n",
    "            images.append(load_nii_file(path))\n",
    "        else: \n",
    "            images.append(load_nii_file(path).astype(d_type))\n",
    "    return images\n",
    "\n",
    "\n",
    "def to_onehot(matrix, labels=[], single_foregound_lable=True, background_channel=True, onehot_type=np.dtype(np.float32)):\n",
    "    matrix = np.around(matrix)\n",
    "    if len(labels) == 0:\n",
    "        labels = np.unique(matrix) \n",
    "        labels = labels[1::]\n",
    "    \n",
    "    mask = np.zeros(matrix.shape, dtype=onehot_type)\n",
    "    for i, label in enumerate(labels):\n",
    "        mask += ((matrix == label) * (i+1))\n",
    "   \n",
    "    if single_foregound_lable:\n",
    "        mask = (mask > 0)\n",
    "        labels = [1]\n",
    "        \n",
    "    labels_len = len(labels)        \n",
    "        \n",
    "    onehot = np.zeros((labels_len+1,) + matrix.shape, dtype=onehot_type) \n",
    "    for i in range(mask.max()+1):\n",
    "        onehot[i] = (mask == i)  \n",
    "        \n",
    "    if background_channel == False:\n",
    "        onehot = onehot[1::] \n",
    "        \n",
    "       \n",
    "    return mask, onehot, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segmentor(pl.LightningModule):\n",
    "    def __init__(self, hparams: argparse.Namespace):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters(hparams)        \n",
    "\n",
    "        if \"unet\" in self.hparams.cnn_architecture:\n",
    "            architecture = UNet(nin_channels=self.hparams.n_inchannels, \n",
    "                                nout_channels=self.hparams.n_outchannels, \n",
    "                                init_features=self.hparams.init_features)\n",
    "        elif self.hparams.cnn_architecture == \"coedet\":\n",
    "            architecture = CoEDET(nin=self.hparams.n_inchannels, nout=self.hparams.n_outchannels, \n",
    "                                  apply_sigmoid=self.hparams.apply_sigmoid)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported cnn_architecture {self.hparams.cnn_architecture}\")\n",
    "\n",
    "        self.model = architecture\n",
    "    \n",
    "        \n",
    "        ttransform_scale=None\n",
    "        ttransform_angle=None\n",
    "        ttransform_flip_prob=None\n",
    "        ttransform_sigma=None\n",
    "        ttransform_ens_treshold=None\n",
    "        if \"taug_scale\" in self.hparams:\n",
    "            ttransform_scale = self.hparams.taug_scale\n",
    "        if \"taug_angle\" in self.hparams:\n",
    "            ttransform_angle = self.hparams.taug_angle\n",
    "        if \"taug_flip_prob\" in self.hparams:\n",
    "            ttransform_flip_prob = self.hparams.taug_flip_prob\n",
    "        if \"taug_sigma\" in self.hparams:\n",
    "            ttransform_sigma = self.hparams.taug_sigma\n",
    "        if \"taug_ens_treshold\" in self.hparams:\n",
    "            ttransform_ens_treshold = self.hparams.aug_ens_treshold\n",
    "        self.train_transforms = My_transforms(scale=ttransform_scale,\n",
    "                                         angle=ttransform_angle,\n",
    "                                         flip_prob=ttransform_flip_prob,\n",
    "                                         sigma=ttransform_sigma,\n",
    "                                         ens_treshold=ttransform_ens_treshold\n",
    "                                        )\n",
    "        vtransform_scale=None\n",
    "        vtransform_angle=None\n",
    "        vtransform_flip_prob=None\n",
    "        vtransform_sigma=None\n",
    "        vtransform_ens_treshold=None\n",
    "        if \"vaug_scale\" in self.hparams:\n",
    "            ttransform_scale = self.hparams.vaug_scale\n",
    "        if \"vaug_angle\" in self.hparams:\n",
    "            ttransform_angle = self.hparams.vaug_angle\n",
    "        if \"vaug_flip_prob\" in self.hparams:\n",
    "            ttransform_flip_prob = self.hparams.vaug_flip_prob\n",
    "        if \"vaug_sigma\" in self.hparams:\n",
    "            ttransform_sigma = self.hparams.vaug_sigma\n",
    "        if \"vaug_ens_treshold\" in self.hparams:\n",
    "            ttransform_ens_treshold = self.hparams.vaug_ens_treshold\n",
    "        self.val_transforms = My_transforms(scale=vtransform_scale,\n",
    "                                         angle=vtransform_angle,\n",
    "                                         flip_prob=vtransform_flip_prob,\n",
    "                                         sigma=vtransform_sigma,\n",
    "                                         ens_treshold=vtransform_ens_treshold\n",
    "                                        )\n",
    "        \n",
    "  \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        loss = None\n",
    "\n",
    "        x, y = train_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = CombinedLoss(logits, y, \n",
    "                            self.hparams.train_loss_funcs, \n",
    "                            self.hparams.lossweighs,\n",
    "                            func_weights=self.hparams.func_weights)\n",
    "\n",
    "        if self.hparams.train_metric == 'DiceMetric_weighs':\n",
    "            train_metric = DiceMetric_weighs(y_pred=logits, y_true=y,\n",
    "                                             weights=self.hparams.train_metricweighs, treshold=0.5)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric {self.hparams.train_metric}\")\n",
    "\n",
    "        self.log(\"loss\", loss, on_epoch=True, on_step=True)\n",
    "        self.log(\"train_metric\", train_metric, on_epoch=True, on_step=False)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        logits = None\n",
    "\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = CombinedLoss(logits, y, \n",
    "                            self.hparams.val_loss_funcs, \n",
    "                            self.hparams.lossweighs,\n",
    "                            func_weights=self.hparams.func_weights)\n",
    "    \n",
    "        if self.hparams.val_metric == 'DiceMetric_weighs':\n",
    "            val_metric = DiceMetric_weighs(y_pred=logits, y_true=y,\n",
    "                                             weights=self.hparams.val_metricweighs, treshold=0.5)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported metric {self.hparams.val_metric}\")\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_metric\", val_metric, on_epoch=True, on_step=False, prog_bar=True)\n",
    "\n",
    "\n",
    "        \n",
    "        self.log(\"learning_rate_test\", self.optimizer.param_groups[0]['lr'], on_epoch=True, on_step=False, prog_bar=False)\n",
    "\n",
    "    \n",
    "    def get_optimizer_by_name(self, name, lr):\n",
    "        '''\n",
    "        Note que você pode adicionar funções suas ao LightningModule \n",
    "        Defini essa função para poder selecionar o otimizador por uma string.\n",
    "        '''\n",
    "        if name == \"Adam\":\n",
    "            return Adam(self.model.parameters(), lr=lr)\n",
    "        elif name == \"SGD\":\n",
    "            return SGD(self.model.parameters(), lr=lr)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported optimizer: {name}\")\n",
    "            \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        '''\n",
    "        Select optimizer and scheduling strategy according to hparams.\n",
    "        '''\n",
    "        optimizer = self.get_optimizer_by_name(self.hparams.opt_name, \n",
    "                                               self.hparams.lr)\n",
    "\n",
    "        if self.hparams.lr_decay_policy == 'step':\n",
    "            scheduler = StepLR(optimizer, self.hparams.scheduling_patience_lrepochs, self.hparams.lr_decay_factor, verbose=True)\n",
    "            print('STEP - scheduling_patience_lrepochs = ', self.hparams.scheduling_patience_lrepochs, ' lr_decay_factor = ', self.hparams.lr_decay_factor)\n",
    "        elif self.hparams.lr_decay_policy == 'plateau':\n",
    "            print('PLATEAU - scheduling_patience_lrepochs = ', self.hparams.scheduling_patience_lrepochs, ' lr_decay_factor = ', self.hparams.lr_decay_factor)\n",
    "\n",
    "            self.optimizer = optimizer\n",
    "            lr_scheduler =  {\n",
    "                           'scheduler': ReduceLROnPlateau(optimizer),\n",
    "                           'mode': self.hparams.lr_decay_mode,\n",
    "                           'factor': self.hparams.lr_decay_factor,\n",
    "                           'patience': self.hparams.scheduling_patience_lrepochs,\n",
    "                           'threshold': 0.0001,\n",
    "                           'threshold_mode': self.hparams.lr_decay_threshold_mode,\n",
    "                           'cooldown': 0,\n",
    "                           'min_lr': 0,\n",
    "                           'eps': 1e-08,\n",
    "                           'monitor': 'val_loss',\n",
    "                           'verbose': True\n",
    "                           }\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
    "        \n",
    "         \n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported lr_decay_policy {self.hparams.lr_decay_policy}\")\n",
    "            \n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #fine tuning freeze\n",
    "#all channels:\n",
    "axial_model_path = \"./checkpoints/fine_tuning_unet_single_label_freeze/unet_single_label_psz064_axial_15-11-2021_20-29-epoch=03-val_loss=0.11.ckpt\"\n",
    "coronal_model_path = \"./checkpoints/fine_tuning_unet_single_label_freeze/unet_single_label_psz064_coronal_15-11-2021_20-47-epoch=02-val_loss=0.11.ckpt\"\n",
    "sagittal_model_path = \"./checkpoints/fine_tuning_unet_single_label_freeze/unet_single_label_psz064_sagittal_15-11-2021_21-48-epoch=04-val_loss=0.11.ckpt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "dataset_folder = './Data/HCP_processed_data/'\n",
    "\n",
    "dest_folder = './Predictions/fine_tuning_unet_single_label_freeze/all_channels/'\n",
    "os.makedirs(dest_folder, exist_ok=True)\n",
    "\n",
    "subject_list = 'inference_input.txt'\n",
    "\n",
    "# Experiment definition\n",
    "experiment_name = 'single_label'\n",
    "Slice_views = ['axial', 'coronal', 'sagittal']\n",
    "\n",
    "\n",
    "percentil_filt = 99.98\n",
    "normalize_volumes = [0,1]\n",
    "\n",
    "prediction_threshold = 0.5\n",
    "\n",
    "\n",
    "\n",
    "evalue1_sufix = 'diffusion/evalue1.nii.gz'\n",
    "FA_sufix = 'diffusion/FA.nii.gz'\n",
    "RD_sufix = 'diffusion/RD.nii.gz'\n",
    "MD_sufix = 'diffusion/MD.nii.gz'\n",
    "T1_sufix = 'T1w_acpc_dc_restore_1.25.nii.gz'\n",
    "img_paths = [evalue1_sufix, FA_sufix, RD_sufix, MD_sufix, T1_sufix]\n",
    "\n",
    "\n",
    "mask_free_sufix = 'FreeSurfer/aparc+aseg_1.25_nearest.nii.gz'\n",
    "\n",
    "save_prediction = True\n",
    "\n",
    "input_d_type='float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject =  100206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/95579505.py:3: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  volume = np.nan_to_num(data.get_data().squeeze())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 24.8 s, total: 1min 41s\n",
      "Wall time: 15.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:63: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "subjects = [line.strip() for line in open(subject_list)]\n",
    "\n",
    "MASKS = []\n",
    "STAPLE = []\n",
    "FREE = []\n",
    "FSL = []\n",
    "QUI = []\n",
    "MAN = []\n",
    "PREDICTIONS = []\n",
    "PREDICTIONS_fullsize = []\n",
    "\n",
    "for subject in subjects:\n",
    "    print('subject = ', subject)\n",
    "        \n",
    "    images = load_files([dataset_folder + subject + '/' +  s for s in img_paths])\n",
    "\n",
    "    if percentil_filt > 0:\n",
    "        for i in range(len(images)):\n",
    "            images[i][images[i] > np.percentile(images[i], percentil_filt)] = np.percentile(images[i], percentil_filt)\n",
    "    \n",
    "    if len(normalize_volumes) == 2:\n",
    "        for i in range(len(images)):\n",
    "            images[i] = images[i] * ((normalize_volumes[1]-normalize_volumes[0])/(images[i].max()-images[i].min()))\n",
    "            images[i] = images[i] - images[i].min() + normalize_volumes[0]          \n",
    "   \n",
    "    img_crop = np.array(images)[:, :144, 15:159, :144]\n",
    "    \n",
    "    PREDS = []\n",
    "    for Slice_view in Slice_views:\n",
    "        \n",
    "        # reorient images\n",
    "        if Slice_view == 'axial':\n",
    "            img_crop_reoriented = np.transpose(img_crop, (3, 0, 1, 2))\n",
    "            model_path = axial_model_path\n",
    "        elif Slice_view == 'coronal':\n",
    "            img_crop_reoriented = np.transpose(img_crop, (2, 0, 1, 3))\n",
    "            model_path = coronal_model_path\n",
    "        elif Slice_view == 'sagittal':\n",
    "            img_crop_reoriented = np.transpose(img_crop, (1, 0, 2, 3))\n",
    "            model_path = sagittal_model_path\n",
    "\n",
    "        trained_model = Segmentor.load_from_checkpoint(model_path).eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = trained_model(torch.tensor(img_crop_reoriented)).cpu().numpy()\n",
    "\n",
    "        # reorient images\n",
    "        if Slice_view == 'axial':\n",
    "            preds = np.transpose(preds, (1, 2, 3, 0))\n",
    "        elif Slice_view == 'coronal':\n",
    "            preds = np.transpose(preds, (1, 2, 0, 3))\n",
    "        elif Slice_view == 'sagittal':\n",
    "            preds = np.transpose(preds, (1, 0, 2, 3))\n",
    "\n",
    "        PREDS.append(preds) #prediction for each slice\n",
    "    \n",
    "    prediction = np.zeros(preds.shape)\n",
    "    for pred in PREDS:\n",
    "        prediction = prediction + pred/len(PREDS)\n",
    "    \n",
    "    if save_prediction:\n",
    "        FREE_file = ni.load(dataset_folder + subject + '/' + mask_free_sufix)\n",
    "        FREE_data = FREE_file.get_data()  \n",
    "                            \n",
    "        PREDICTION_fullsize = np.zeros(images[0].shape)\n",
    "        PREDICTION_fullsize[:144, 15:159, :144] = (prediction[1] >= prediction_threshold)  #save only the thalamus channel\n",
    "        PREDICTIONS_fullsize.append(PREDICTION_fullsize)\n",
    "        prediction_file = ni.Nifti1Image(PREDICTION_fullsize.astype(FREE_data.dtype), affine=FREE_file.affine, header=FREE_file.header)\n",
    "        ni.save(prediction_file, dest_folder + subject + '.nii.gz')\n",
    "        \n",
    "    PREDICTIONS.append(np.asarray(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs are on the Predictions folder!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
